# services/scraper_service.py

import requests
import json
from pathlib import Path
from bs4 import BeautifulSoup
from cachetools import cached, TTLCache

from core.config import (
    BASE_URL,
    RESULT_URL,
    REQUEST_TIMEOUT,
    logger,
)

class ScraperService:
    """
    Ø®Ø¯Ù…Ø© Ù…Ø³ØªÙ‚Ù„Ø© Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©.
    """
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': BASE_URL
        })
        selectors_path = Path(__file__).parent / 'selectors.json'
        try:
            with open(selectors_path, 'r', encoding='utf-8') as f:
                self.selectors = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.error(f"ÙØ´Ù„ Ø­Ø§Ø³Ù…: Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§Øª 'selectors.json'. Ø§Ù„Ø®Ø·Ø£: {e}")
            raise RuntimeError("Scraper cannot operate without selectors.") from e

    @cached(cache=TTLCache(maxsize=1, ttl=3600))
    def fetch_colleges_and_token(self):
        """
        ØªØ¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„ÙŠØ§Øª ÙˆØ±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚.
        ÙŠØªÙ… ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¤Ù‚ØªÙ‹Ø§ Ù„Ù…Ø¯Ø© Ø³Ø§Ø¹Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù….
        """
        try:
            response = self.session.get(BASE_URL, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")
            
            token_input = soup.select_one(self.selectors['request_verification_token'])
            if not token_input or 'value' not in token_input.attrs:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚ (__RequestVerificationToken).")
            token = token_input["value"]
            
            college_select = soup.select_one(self.selectors['college_select_dropdown'])
            if not college_select:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø©.")

            college_emojis = { "Ø§Ù„Ø¨Ø´Ø±ÙŠ": "ğŸ‘¨â€âš•ï¸", "Ø§Ù„ØµÙŠØ¯Ù„Ø©": "ğŸ’Š", "Ø§Ù„Ø£Ø³Ù†Ø§Ù†": "ğŸ¦·", "Ø§Ù„Ø¢Ø¯Ø§Ø¨": "ğŸ“š", "Ø§Ù„Ù…Ø¯Ù†ÙŠØ©": "ğŸ—ï¸", "Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©": "ğŸ›ï¸","Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠ": "ğŸ§‘â€ğŸŒ¾", "Ø§Ù„Ø¨ÙŠØ·Ø±ÙŠ": "ğŸ¾", "Ø§Ù„Ø¹Ù„ÙˆÙ…": "ğŸ”¬", "Ø§Ù„ØªØ±Ø¨ÙŠØ©": "ğŸ§‘â€ğŸ«", "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯": "ğŸ“ˆ", "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©": "ğŸ", "Ø§Ù„Ù…ÙŠÙƒØ§Ù†ÙŠÙƒ": "âš™ï¸", "Ø­Ø§Ø³ÙˆØ¨": "ğŸ–¥ï¸"}
            
            colleges = []
            for opt in college_select.select(self.selectors['college_option']):
                value = opt.get("value")
                if not value: continue
                
                name = opt.text.strip()
                emoji = next((emoji for keyword, emoji in college_emojis.items() if keyword in name), "ğŸ“")
                colleges.append({"name": f"{emoji} {name}", "id": value})

            return colleges, token
        
        except (requests.RequestException, ValueError, AttributeError) as e:
            logger.error(f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„ÙƒÙ„ÙŠØ§Øª ÙˆØ±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚: {e}", exc_info=True)
            return None, None

    def fetch_full_student_data(self, college_id: str, university_id: str, token: str):
        """
        ØªØ¬Ù„Ø¨ ÙƒØ§Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆÙ†ØªØ§Ø¦Ø¬Ù‡ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹.
        """
        payload = {
            "UniversityId": university_id,
            "CollegeId": college_id,
            "__RequestVerificationToken": token,
            "Year": ""
        }
        try:
            response = self.session.post(RESULT_URL, data=payload, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")

            if error_div := soup.select_one(self.selectors['validation_error_summary']):
                return {"success": False, "error": error_div.text.strip()}

            student_info = self._parse_student_info(soup)
            all_marks = self._parse_student_marks(soup)

            if not student_info and not all_marks:
                return {"success": False, "error": "Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù„Ù‡ Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„ÙŠØ©."}

            # ÙØ±Ø² Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¯Ø§Ø¦Ù…Ø§ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
            sorted_marks = sorted(all_marks, key=lambda x: (x.get('date', ''), x.get('subject', '')))
            
            return {"success": True, "info": student_info, "marks": sorted_marks}

        except requests.RequestException as e:
            logger.error(f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„Ø¬Ù„Ø¨ Ù„Ù„Ø±Ù‚Ù… {university_id}: {e}", exc_info=True)
            return {"success": False, "error": "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§."}

    def _parse_student_info(self, soup: BeautifulSoup) -> dict:
        """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø´Ø®ØµÙŠØ©."""
        student_info = {}
        info_card = soup.select_one(self.selectors['student_info_card'])
        if not info_card: return student_info

        spans = info_card.select(f"{self.selectors['info_key_span']}, {self.selectors['info_value_span']}")
        i = 0
        while i < len(spans) - 1:
            key_span = spans[i]
            value_span = spans[i+1]
            if 'head' in key_span.get('class', []) and 'bottom' in value_span.get('class', []):
                key_text = key_span.text.strip()
                value_text = value_span.text.strip()
                if "Ø§Ù„Ø§Ø³Ù…" in key_text and "Ø§Ù„Ø£Ø¨" not in key_text: student_info['name'] = value_text
                elif "Ø§Ø³Ù… Ø§Ù„Ø£Ø¨" in key_text: student_info['father_name'] = value_text
                elif "Ø§Ù„ÙƒÙ„ÙŠØ©" in key_text: student_info['college_name'] = value_text
                i += 2
            else:
                i += 1
        return student_info

    def _parse_student_marks(self, soup: BeautifulSoup) -> list:
        """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª."""
        all_marks = []
        result_panels = soup.select(self.selectors['result_panels'])
        for panel in result_panels:
            heading_tag = panel.select_one(self.selectors['panel_heading'])
            heading = heading_tag.text.strip() if heading_tag else "ÙØµÙ„ ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
            
            table = panel.select_one(self.selectors['results_table'])
            if table and (tbody := table.select_one(self.selectors['table_body'])):
                for row in tbody.select(self.selectors['table_row']):
                    cols = [td.text.strip() for td in row.select(self.selectors['table_cell'])]
                    if len(cols) >= 5:
                        all_marks.append({
                            "subject": cols[0], "session": cols[1], "mark": cols[2], 
                            "status": cols[3], "date": cols[4], "semester": heading
                        })
        return all_marks

    @staticmethod
    def find_new_marks(old_marks: list, new_marks: list) -> list:
        """
        ØªÙ‚Ø§Ø±Ù† Ø¨ÙŠÙ† Ù‚Ø§Ø¦Ù…ØªÙŠ Ø¹Ù„Ø§Ù…Ø§Øª ÙˆØªÙØ±Ø¬Ø¹ ÙÙ‚Ø· Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.
        ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…ØªÙŠÙ† Ù…Ø±ØªØ¨ØªÙŠÙ†.
        """
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… set Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø³Ø±ÙŠØ¹Ø© ÙˆÙØ¹Ø§Ù„Ø©
        old_marks_set = {json.dumps(mark, sort_keys=True) for mark in old_marks}
        new_marks_list = []
        for mark in new_marks:
            if json.dumps(mark, sort_keys=True) not in old_marks_set:
                new_marks_list.append(mark)
        return new_marks_list